\subsection{Linear Algebra}

A \textbf{vector space} over a field $F$ is a set $V$ with two operations, addition $+: V \times V \to V$ and scalar multiplication $\cdot: F \times V \to V$, that satisfy the following axioms.
\begin{align}
    \forall u, v, w \in V: \qquad & u + (v + w) = (u + v) + w & \text{associativity of vector addition} \\
    \forall u, v \in V: \qquad & u + v = v + u & \text{commutativity of vector addition} \\
    \exists 0_V \in V\ \forall v \in V: \qquad & v + 0_V = v & \text{identity element of vector addition} \\
    \forall v \in V\ \exists -v \in V: \qquad & -v + v = 0_V & \text{inverse element of vector addition} \\
    \forall v \in V\ a, b \in F: \qquad & a \cdot (b \cdot v) = (a \cdot b) \cdot v & \text{compatibility of multiplications\footnotemark} \\
    \forall v \in V: \qquad & 1 \cdot v = v & \text{identity element of scalar multiplication} \\
    \forall u, v \in V\ a \in F: \qquad & a \cdot (u + v) = a \cdot u + a \cdot v & \text{distributivity of scalar multiplication\footnotemark} \\
    \forall v \in V\ a, b \in F: \qquad & (a + b) \cdot v = a \cdot v + b \cdot v & \text{distributivity of scalar multiplication\footnotemark}
\end{align}
\footnotetext{compatibility of scalar multiplication and field multiplication}
\footnotetext{with respect to vector addition}
\footnotetext{with respect to field addition}

A \textbf{linear map} $m$ between vector spaces $V$ and $W$ is a map $m: V \to W$ that satisfies the following two conditions.
\begin{align}
    \forall u, v \in V: \qquad & m(u + v) = m(u) + m(v) & \text{additivity} \\
    \forall c \in \C, v \in V: \qquad & m(c \cdot v) = c \cdot m(v) & \text{homogeneity}
\end{align}
In our case both vector spaces $V$ and $W$ always have the same, so $V = W$.
The set of all linear maps between $V$ and itself is denoted as $\GL(V)$.
\\

In most cases, the representations of groups are over finite-dimensional vector spaces.
If they are finite-dimensional, they will be vector spaces over the field of complex numbers $\C$ in this work.
A $n$-dimensional complex vector space is denoted as $\C^n$.

If a linear map is between two finite-dimensional vector spaces and both of those have a defined basis, it can be represented by a \textbf{matrix}.
In our finite-dimensional cases, both vector spaces are $\C^n$ and we define the standard basis $\{e_i | 0 \leq i < n\}$ where $e_i = \begin{pmatrix} 0 & \ldots & 0 & 1 & 0 & \ldots & 0 \end{pmatrix}^T$ is a vector with all zeros except the $i$-th element.
So we can represent the linear maps as vectors in the finite-dimensional cases in this paper.
Matrix multiplication $\cdot: \C^{a \times b} \times \C^{b \times c} \to \C^{a \times c}$ is equivalent to the composition of the linear maps, they represent.
$\C^n$, matrices, and matrix multiplication are common concepts in computer science so I will omit the details here.

On $\C^n$, the \textbf{scalar product} (also called dot product) $\langle \cdot, \cdot \rangle: \C^n \times \C^n \to \C$ is defined as
\begin{align}
    \langle v, w \rangle = \sum_i v_i \cdot w_i
\end{align}
It can also be thought of as a matrix multiplication of a row vector and a column vector $\langle v, w \rangle = v^T w$.

The \textbf{direct sum} of two matrices $\oplus: \C^{a \times b} \times \C^{c \times d} \to \C^{(a + c) \times (b + d)}$ is defined as
\begin{align}
    A \oplus B = \begin{pmatrix}
        A & 0 \\
        0 & B
    \end{pmatrix}
\end{align}
where each zero stands for a matrix that only has zeros.
